{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "47fece30c73144e1a7073925aedbea49": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e210329f81f048f2aacca9bbd379087b",
              "IPY_MODEL_e607d0115594490ba90655a9d8d2a282",
              "IPY_MODEL_f541132404e74ff8b6fd10bf6fb9d21d"
            ],
            "layout": "IPY_MODEL_2bd60f3e4284409e9eb0607404b1342a"
          }
        },
        "e210329f81f048f2aacca9bbd379087b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_94ea6b36b6324e96aa7ec71e64295b9a",
            "placeholder": "​",
            "style": "IPY_MODEL_6bc46ec00e0444d6996c1f374e4439e3",
            "value": "Loading checkpoint shards: 100%"
          }
        },
        "e607d0115594490ba90655a9d8d2a282": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0cc288eeb06e42c59d63d20211e3d40d",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_8d8fe4f5c44f4d98a108b055903fb96e",
            "value": 2
          }
        },
        "f541132404e74ff8b6fd10bf6fb9d21d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_aabb9336b93f48d6a4c890304653c8cb",
            "placeholder": "​",
            "style": "IPY_MODEL_7cca1be8950a401eb5b4e678a3d4e5d5",
            "value": " 2/2 [00:02&lt;00:00,  1.03it/s]"
          }
        },
        "2bd60f3e4284409e9eb0607404b1342a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "94ea6b36b6324e96aa7ec71e64295b9a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6bc46ec00e0444d6996c1f374e4439e3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0cc288eeb06e42c59d63d20211e3d40d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8d8fe4f5c44f4d98a108b055903fb96e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "aabb9336b93f48d6a4c890304653c8cb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7cca1be8950a401eb5b4e678a3d4e5d5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5ba4a320c74148e2bc8b7441eccd54b7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_80b3d64bc02c4ae4bd6faa0df293d64c",
              "IPY_MODEL_10e301db87374286ab418eb3d87c521c",
              "IPY_MODEL_c2a63cdda57348bcb8b1313d2a7325ab"
            ],
            "layout": "IPY_MODEL_2ed4bd9fffb94fa7a7db87b20efce6a5"
          }
        },
        "80b3d64bc02c4ae4bd6faa0df293d64c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_38ae3163d3224f54bdd4f00bb9627348",
            "placeholder": "​",
            "style": "IPY_MODEL_c51aac457e6f4e92a56bb7a01b3ccdaf",
            "value": "Loading checkpoint shards: 100%"
          }
        },
        "10e301db87374286ab418eb3d87c521c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_64df5566b8f24c6f862b84fbac6c3e63",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_394232e548b04ed7b5ce25a47821d588",
            "value": 2
          }
        },
        "c2a63cdda57348bcb8b1313d2a7325ab": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d93b715094ea4944bc3d19777f24ae0d",
            "placeholder": "​",
            "style": "IPY_MODEL_5401d13591214da6b096b9e02869c9c4",
            "value": " 2/2 [00:04&lt;00:00,  2.19s/it]"
          }
        },
        "2ed4bd9fffb94fa7a7db87b20efce6a5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "38ae3163d3224f54bdd4f00bb9627348": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c51aac457e6f4e92a56bb7a01b3ccdaf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "64df5566b8f24c6f862b84fbac6c3e63": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "394232e548b04ed7b5ce25a47821d588": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "d93b715094ea4944bc3d19777f24ae0d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5401d13591214da6b096b9e02869c9c4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "35c52b386284489e813a5c95f8e78ef2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ba7ca98d21614b6aab38a44edc56b2b5",
              "IPY_MODEL_51317162c9e04d2e99cc8de132ed108a",
              "IPY_MODEL_73ca15b1126f4cc5a540839ba211452b"
            ],
            "layout": "IPY_MODEL_1647660adfd74892b6da0fb40f6abeed"
          }
        },
        "ba7ca98d21614b6aab38a44edc56b2b5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_39f16a106dbf4a5f9b7c64af18127f1e",
            "placeholder": "​",
            "style": "IPY_MODEL_0303e281f0d34e458ac5bcce11818570",
            "value": "Loading checkpoint shards: 100%"
          }
        },
        "51317162c9e04d2e99cc8de132ed108a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c394b3b8799a47eebc7aed9923b6761f",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_7d6dd9cacaf544a3b1ec127dfbd02518",
            "value": 2
          }
        },
        "73ca15b1126f4cc5a540839ba211452b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_35f0259b81e142e8aa50cb36787176ac",
            "placeholder": "​",
            "style": "IPY_MODEL_4371df7423d345788282eadcfdca394d",
            "value": " 2/2 [00:02&lt;00:00,  1.00it/s]"
          }
        },
        "1647660adfd74892b6da0fb40f6abeed": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "39f16a106dbf4a5f9b7c64af18127f1e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0303e281f0d34e458ac5bcce11818570": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c394b3b8799a47eebc7aed9923b6761f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7d6dd9cacaf544a3b1ec127dfbd02518": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "35f0259b81e142e8aa50cb36787176ac": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4371df7423d345788282eadcfdca394d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "775749b482274e8da89378fc7e25bdd3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_0648f5dbb2644a38a2f5cd2f8ad4a360",
              "IPY_MODEL_732c28debf354c868aa8369fe4898ece",
              "IPY_MODEL_d1d5b78fd278461598c41495cea727f0"
            ],
            "layout": "IPY_MODEL_0429ea2be82d437cbaf55bebd03ade59"
          }
        },
        "0648f5dbb2644a38a2f5cd2f8ad4a360": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_32934779267d47c5bbef9817f8799076",
            "placeholder": "​",
            "style": "IPY_MODEL_36c175a6bd464ae5bd7a6cc2f35bc8d5",
            "value": "Map: 100%"
          }
        },
        "732c28debf354c868aa8369fe4898ece": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f0ebd1e4e29e4386a63e9472e5258a93",
            "max": 90,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_dcc108cd001d483a9f9c11c37b2808a1",
            "value": 90
          }
        },
        "d1d5b78fd278461598c41495cea727f0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_585467f24b7742e6a939d670c5e7da01",
            "placeholder": "​",
            "style": "IPY_MODEL_64541c6eae3747eb9e0e150f09dc7224",
            "value": " 90/90 [00:00&lt;00:00, 376.64 examples/s]"
          }
        },
        "0429ea2be82d437cbaf55bebd03ade59": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "32934779267d47c5bbef9817f8799076": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "36c175a6bd464ae5bd7a6cc2f35bc8d5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f0ebd1e4e29e4386a63e9472e5258a93": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dcc108cd001d483a9f9c11c37b2808a1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "585467f24b7742e6a939d670c5e7da01": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "64541c6eae3747eb9e0e150f09dc7224": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "39f13eab197447a99c137f2596502b88": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ef38adbcc97743d68b136bd410dd962b",
              "IPY_MODEL_100b538473ff4e7daf8c5acf5c963e91",
              "IPY_MODEL_e2dfda00146b46fc82e547d49284fbf5"
            ],
            "layout": "IPY_MODEL_01c1381f1bc1410b9ffe28237964ef85"
          }
        },
        "ef38adbcc97743d68b136bd410dd962b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9165620fe1ff42d8961425fa5aba1ed0",
            "placeholder": "​",
            "style": "IPY_MODEL_1e30d61e5f894ce99eff2a197842c986",
            "value": "Map: 100%"
          }
        },
        "100b538473ff4e7daf8c5acf5c963e91": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_375e4d9f0ab847709372084a573c7dbf",
            "max": 10,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_efca6a7b92994943b3d80943cb5f8fb4",
            "value": 10
          }
        },
        "e2dfda00146b46fc82e547d49284fbf5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_800314547a1d41bc81b97bc48e92035c",
            "placeholder": "​",
            "style": "IPY_MODEL_20f4d5b2c43f4332b6489c5a7abf8f11",
            "value": " 10/10 [00:00&lt;00:00, 216.19 examples/s]"
          }
        },
        "01c1381f1bc1410b9ffe28237964ef85": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9165620fe1ff42d8961425fa5aba1ed0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1e30d61e5f894ce99eff2a197842c986": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "375e4d9f0ab847709372084a573c7dbf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "efca6a7b92994943b3d80943cb5f8fb4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "800314547a1d41bc81b97bc48e92035c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "20f4d5b2c43f4332b6489c5a7abf8f11": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "08167a256250414fa23567ab452e2f10": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_74d6c58237df484286d0b8659b32c374",
              "IPY_MODEL_500eddb075b84ca5931f176ae40b84f1",
              "IPY_MODEL_2e64ceb5a21241c9b1fb0e21c6278fa3"
            ],
            "layout": "IPY_MODEL_b163bbc215be4369baf89b2f14bf377e"
          }
        },
        "74d6c58237df484286d0b8659b32c374": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cfa70b80466f4c49a880e3f5f13afb49",
            "placeholder": "​",
            "style": "IPY_MODEL_b553ef035d894956891feb04229d4780",
            "value": "Map: 100%"
          }
        },
        "500eddb075b84ca5931f176ae40b84f1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_367a31de22464d60b5f8faf05e2db578",
            "max": 90,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_76014a32b7b34b66afad76f4c4849566",
            "value": 90
          }
        },
        "2e64ceb5a21241c9b1fb0e21c6278fa3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_160330be24de47f69c56e849a88a2eb7",
            "placeholder": "​",
            "style": "IPY_MODEL_9d624850e7a545749b1eed481928ed5e",
            "value": " 90/90 [00:00&lt;00:00, 1235.71 examples/s]"
          }
        },
        "b163bbc215be4369baf89b2f14bf377e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cfa70b80466f4c49a880e3f5f13afb49": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b553ef035d894956891feb04229d4780": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "367a31de22464d60b5f8faf05e2db578": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "76014a32b7b34b66afad76f4c4849566": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "160330be24de47f69c56e849a88a2eb7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9d624850e7a545749b1eed481928ed5e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dkyl5QEfYXub",
        "outputId": "ed8977ad-8fb5-48a6-cc6b-9f3cec4722f4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Step 1: Install All the Required Packages**"
      ],
      "metadata": {
        "id": "mFulokCaZLHs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q accelerate==0.21.0 peft==0.4.0 bitsandbytes==0.40.2 transformers==4.31.0 trl==0.4.7"
      ],
      "metadata": {
        "id": "yMocf2iDYuH9"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U accelerate"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A46WFHtcgROV",
        "outputId": "c1858d04-8643-4bb1-8b16-94b6227b78ec"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: accelerate in /usr/local/lib/python3.10/dist-packages (0.21.0)\n",
            "Collecting accelerate\n",
            "  Using cached accelerate-0.34.2-py3-none-any.whl.metadata (19 kB)\n",
            "Requirement already satisfied: numpy<3.0.0,>=1.17 in /usr/local/lib/python3.10/dist-packages (from accelerate) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (24.1)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from accelerate) (6.0.2)\n",
            "Requirement already satisfied: torch>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (2.4.1+cu121)\n",
            "Requirement already satisfied: huggingface-hub>=0.21.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (0.24.7)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.10/dist-packages (from accelerate) (0.4.5)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.21.0->accelerate) (3.16.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.21.0->accelerate) (2024.6.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.21.0->accelerate) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.21.0->accelerate) (4.66.5)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.21.0->accelerate) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (1.13.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.1.4)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.10.0->accelerate) (2.1.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.21.0->accelerate) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.21.0->accelerate) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.21.0->accelerate) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.21.0->accelerate) (2024.8.30)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.10.0->accelerate) (1.3.0)\n",
            "Using cached accelerate-0.34.2-py3-none-any.whl (324 kB)\n",
            "Installing collected packages: accelerate\n",
            "  Attempting uninstall: accelerate\n",
            "    Found existing installation: accelerate 0.21.0\n",
            "    Uninstalling accelerate-0.21.0:\n",
            "      Successfully uninstalled accelerate-0.21.0\n",
            "Successfully installed accelerate-0.34.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade datasets"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rXeGhbsoa7jH",
        "outputId": "4b27b1a6-9354-4bb9-eb68-9753df477932"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: datasets in /usr/local/lib/python3.10/dist-packages (3.0.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets) (3.16.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (1.26.4)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (17.0.0)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (2.1.4)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.10/dist-packages (from datasets) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.10/dist-packages (from datasets) (4.66.5)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets) (3.5.0)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.10/dist-packages (from datasets) (0.70.16)\n",
            "Requirement already satisfied: fsspec<=2024.6.1,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]<=2024.6.1,>=2023.1.0->datasets) (2024.6.1)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.10.5)\n",
            "Requirement already satisfied: huggingface-hub>=0.22.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.24.7)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets) (24.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (6.0.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (2.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.1.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.11.1)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.22.0->datasets) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (2024.8.30)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Step 2: Import All the Required Libraries**"
      ],
      "metadata": {
        "id": "AFXGFj_eZRHN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import torch\n",
        "from datasets import load_dataset\n",
        "from transformers import (\n",
        "    AutoModelForCausalLM,\n",
        "    AutoTokenizer,\n",
        "    BitsAndBytesConfig,\n",
        "    HfArgumentParser,\n",
        "    TrainingArguments,\n",
        "    pipeline,\n",
        "    logging,\n",
        "    AutoModelForSequenceClassification,\n",
        "    Trainer, EarlyStoppingCallback, DataCollatorWithPadding\n",
        ")\n",
        "from trl import SFTTrainer\n",
        "import torch\n",
        "from transformers import LlamaForSequenceClassification, LlamaTokenizer\n",
        "from transformers import LlamaForCausalLM, LlamaTokenizer, pipeline\n",
        "from peft import LoraConfig, get_peft_model, PeftModel, prepare_model_for_int8_training\n",
        "from datasets import load_dataset"
      ],
      "metadata": {
        "id": "wggwpMazZSXn"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Step 3: Loging to HuggingFace**"
      ],
      "metadata": {
        "id": "IPwB3kT2Zw-6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!huggingface-cli login"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ArtxxB6uZ3mI",
        "outputId": "f9d82c3e-7d55-4620-d7f0-f56f61d91d3f"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "    _|    _|  _|    _|    _|_|_|    _|_|_|  _|_|_|  _|      _|    _|_|_|      _|_|_|_|    _|_|      _|_|_|  _|_|_|_|\n",
            "    _|    _|  _|    _|  _|        _|          _|    _|_|    _|  _|            _|        _|    _|  _|        _|\n",
            "    _|_|_|_|  _|    _|  _|  _|_|  _|  _|_|    _|    _|  _|  _|  _|  _|_|      _|_|_|    _|_|_|_|  _|        _|_|_|\n",
            "    _|    _|  _|    _|  _|    _|  _|    _|    _|    _|    _|_|  _|    _|      _|        _|    _|  _|        _|\n",
            "    _|    _|    _|_|      _|_|_|    _|_|_|  _|_|_|  _|      _|    _|_|_|      _|        _|    _|    _|_|_|  _|_|_|_|\n",
            "\n",
            "    A token is already saved on your machine. Run `huggingface-cli whoami` to get more information or `huggingface-cli logout` if you want to log out.\n",
            "    Setting a new token will erase the existing one.\n",
            "    To login, `huggingface_hub` requires a token generated from https://huggingface.co/settings/tokens .\n",
            "Enter your token (input will not be visible): \n",
            "Add token as git credential? (Y/n) Y\n",
            "Token is valid (permission: fineGrained).\n",
            "\u001b[1m\u001b[31mCannot authenticate through git-credential as no helper is defined on your machine.\n",
            "You might have to re-authenticate when pushing to the Hugging Face Hub.\n",
            "Run the following command in your terminal in case you want to set the 'store' credential helper as default.\n",
            "\n",
            "git config --global credential.helper store\n",
            "\n",
            "Read https://git-scm.com/book/en/v2/Git-Tools-Credential-Storage for more details.\u001b[0m\n",
            "Token has not been saved to git credential helper.\n",
            "Your token has been saved to /root/.cache/huggingface/token\n",
            "Login successful\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Step 4: Load or Extract Dataset**"
      ],
      "metadata": {
        "id": "JkwOIu-hZi0d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the dataset\n",
        "train_file = \"/content/drive/MyDrive/model_Train_Assingnment/train.jsonl\"\n",
        "test_file = \"/content/drive/MyDrive/model_Train_Assingnment/test.jsonl\""
      ],
      "metadata": {
        "id": "_x27DDOWZkjd"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load your training and validation data\n",
        "train_dataset = load_dataset('json', data_files='/content/drive/MyDrive/model_Train_Assingnment/train.jsonl', split=\"train\")\n",
        "valid_dataset = load_dataset('json', data_files='/content/drive/MyDrive/model_Train_Assingnment/test.jsonl', split=\"train\")"
      ],
      "metadata": {
        "id": "s-7gGgNBbm7d"
      },
      "execution_count": 116,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(train_dataset.column_names)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nFK5XLPLbpk-",
        "outputId": "91ccb4bc-ac64-4261-df80-c021e37e5b0e"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['prompt', 'response']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Step 5: Model and Tokenizer Configuration**"
      ],
      "metadata": {
        "id": "XDTZT544mB23"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_name = 'NousResearch/Llama-2-7b-chat-hf'"
      ],
      "metadata": {
        "id": "MeiNUnnHmBa9"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load tokenizer\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name, trust_remote_code=True)\n",
        "tokenizer.pad_token = tokenizer.eos_token\n",
        "tokenizer.padding_side = \"right\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GUnVd17XmIB9",
        "outputId": "8b0f2bfe-0e6c-48bd-b8d5-182e15fe636d"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1150: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:89: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Step 5: Define LoRA Configuration**\n",
        "1. **Load a llama-2-7b-chat-hf model (chat model)**\n",
        "2. **Train it on the mlabonne/guanaco-llama2-1k (1,000 samples),**\n",
        "\n",
        " **which will produce our fine-tuned model Llama-2-7b-chat-finetun**"
      ],
      "metadata": {
        "id": "3faRGuACcKVO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Assuming you have a model_name defined somewhere\n",
        "model_name = 'NousResearch/Llama-2-7b-chat-hf'\n",
        "lora_alpha = 16\n",
        "lora_dropout = 0.05\n",
        "lora_r = 8\n",
        "\n",
        "# Load the model\n",
        "model = AutoModelForCausalLM.from_pretrained(model_name, trust_remote_code=True)\n",
        "\n",
        "# Now you can configure the model\n",
        "model.config.use_cache = False\n",
        "model.config.pretraining_tp = 1\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name, trust_remote_code=True)\n",
        "tokenizer.pad_token = tokenizer.eos_token\n",
        "tokenizer.padding_side = \"right\"\n",
        "peft_config = LoraConfig(\n",
        "    lora_alpha=lora_alpha,\n",
        "    lora_dropout=lora_dropout,\n",
        "    r=lora_r,\n",
        "    bias=\"none\",\n",
        "    task_type=\"CAUSAL_LM\",\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "47fece30c73144e1a7073925aedbea49",
            "e210329f81f048f2aacca9bbd379087b",
            "e607d0115594490ba90655a9d8d2a282",
            "f541132404e74ff8b6fd10bf6fb9d21d",
            "2bd60f3e4284409e9eb0607404b1342a",
            "94ea6b36b6324e96aa7ec71e64295b9a",
            "6bc46ec00e0444d6996c1f374e4439e3",
            "0cc288eeb06e42c59d63d20211e3d40d",
            "8d8fe4f5c44f4d98a108b055903fb96e",
            "aabb9336b93f48d6a4c890304653c8cb",
            "7cca1be8950a401eb5b4e678a3d4e5d5"
          ]
        },
        "id": "pgcHnHUDfJ0E",
        "outputId": "9b231fd2-fc3a-4219-ed6f-b321fe8ad3a5"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "47fece30c73144e1a7073925aedbea49"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# LoRA settings for fine-tuning\n",
        "lora_config = LoraConfig(\n",
        "    r=64,  # Low-rank dimension\n",
        "    lora_alpha=16,  # Scaling factor\n",
        "    lora_dropout=0.1,  # Dropout for LoRA layers\n",
        "    bias=\"none\",  # Don't train bias terms\n",
        "    task_type=\"CAUSAL_LM\",  # LoRA task type\n",
        ")"
      ],
      "metadata": {
        "id": "Tt58-vqpcQ7G"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ---- Step 5: Define QLoRA Configuration (bitsandbytes 4-bit quantization) ----\n",
        "bnb_config = BitsAndBytesConfig(\n",
        "    load_in_4bit=True,  # Enable 4-bit quantization\n",
        "    bnb_4bit_compute_dtype=torch.float16,  # Use FP16 precision for computation\n",
        "    bnb_4bit_quant_type=\"nf4\",  # Set quantization type to nf4\n",
        "    bnb_4bit_use_double_quant=False,  # Disable nested quantization\n",
        ")\n"
      ],
      "metadata": {
        "id": "idTufVIMdn7F"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Step 6: Load the Llama-2 Model with QLoRA**"
      ],
      "metadata": {
        "id": "5aWlb0R7dvC1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the model in 4-bit mode with QLoRA\n",
        "model = LlamaForCausalLM.from_pretrained(\n",
        "    'NousResearch/Llama-2-7b-chat-hf',  # Pre-trained model\n",
        "    quantization_config=bnb_config,  # 4-bit quantization setup\n",
        "    device_map=\"auto\",  # Automatically map the model across devices (if using multiple GPUs)\n",
        "    use_auth_token=True  # Use your Hugging Face token if necessary\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104,
          "referenced_widgets": [
            "5ba4a320c74148e2bc8b7441eccd54b7",
            "80b3d64bc02c4ae4bd6faa0df293d64c",
            "10e301db87374286ab418eb3d87c521c",
            "c2a63cdda57348bcb8b1313d2a7325ab",
            "2ed4bd9fffb94fa7a7db87b20efce6a5",
            "38ae3163d3224f54bdd4f00bb9627348",
            "c51aac457e6f4e92a56bb7a01b3ccdaf",
            "64df5566b8f24c6f862b84fbac6c3e63",
            "394232e548b04ed7b5ce25a47821d588",
            "d93b715094ea4944bc3d19777f24ae0d",
            "5401d13591214da6b096b9e02869c9c4"
          ]
        },
        "id": "eQeKakt4dy-N",
        "outputId": "424183bd-55da-4054-c08a-f204110fb77a"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/modeling_utils.py:2193: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "5ba4a320c74148e2bc8b7441eccd54b7"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Prepare model for 8-bit or 4-bit training\n",
        "model = prepare_model_for_int8_training(model)\n",
        "\n",
        "# Apply LoRA to the model\n",
        "model = get_peft_model(model, lora_config)\n",
        "\n",
        "# ---- Step 7: Tokenize the Dataset ----\n",
        "tokenizer = LlamaTokenizer.from_pretrained('NousResearch/Llama-2-7b-chat-hf')\n",
        "\n",
        "# Tokenize the dataset (adjust column names as needed)\n",
        "def tokenize_function(examples):\n",
        "    return tokenizer(examples['prompt'], truncation=True, padding='max_length', max_length=512)\n",
        "\n",
        "train_dataset = train_dataset.map(tokenize_function, batched=True)\n",
        "valid_dataset = valid_dataset.map(tokenize_function, batched=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r-wegMbwd7AJ",
        "outputId": "b4dee16b-5023-49ac-b860-6f8e2098d6e9"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/peft/utils/other.py:102: FutureWarning: prepare_model_for_int8_training is deprecated and will be removed in a future version. Use prepare_model_for_kbit_training instead.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load model\n",
        "model = AutoModelForCausalLM.from_pretrained(model_name, trust_remote_code=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "35c52b386284489e813a5c95f8e78ef2",
            "ba7ca98d21614b6aab38a44edc56b2b5",
            "51317162c9e04d2e99cc8de132ed108a",
            "73ca15b1126f4cc5a540839ba211452b",
            "1647660adfd74892b6da0fb40f6abeed",
            "39f16a106dbf4a5f9b7c64af18127f1e",
            "0303e281f0d34e458ac5bcce11818570",
            "c394b3b8799a47eebc7aed9923b6761f",
            "7d6dd9cacaf544a3b1ec127dfbd02518",
            "35f0259b81e142e8aa50cb36787176ac",
            "4371df7423d345788282eadcfdca394d"
          ]
        },
        "id": "lrjqCh1DmObt",
        "outputId": "8447cdaf-77c6-4896-ba31-2b4f8c70699f"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "35c52b386284489e813a5c95f8e78ef2"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.config.use_cache = False"
      ],
      "metadata": {
        "id": "DEfn_HO_mR3V"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Prepare model for 8-bit training (if you're using INT8 or 4-bit quantization)\n",
        "model = prepare_model_for_int8_training(model)\n",
        "\n",
        "# Apply LoRA to the model\n",
        "model = get_peft_model(model, lora_config)\n",
        "\n",
        "# ---- Step 4: Tokenize the Dataset ----\n",
        "def tokenize_function(examples):\n",
        "    # Tokenize the input text and shift labels for causal language modeling\n",
        "    tokenized_inputs = tokenizer(examples['prompt'], truncation=True, padding='max_length', max_length=512)\n",
        "\n",
        "    # Set input_ids as labels for causal language modeling (shifted labels)\n",
        "    tokenized_inputs['labels'] = tokenized_inputs['input_ids'].copy()\n",
        "\n",
        "    return tokenized_inputs\n",
        "\n",
        "train_dataset = train_dataset.map(tokenize_function, batched=True)\n",
        "valid_dataset = valid_dataset.map(tokenize_function, batched=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 81,
          "referenced_widgets": [
            "775749b482274e8da89378fc7e25bdd3",
            "0648f5dbb2644a38a2f5cd2f8ad4a360",
            "732c28debf354c868aa8369fe4898ece",
            "d1d5b78fd278461598c41495cea727f0",
            "0429ea2be82d437cbaf55bebd03ade59",
            "32934779267d47c5bbef9817f8799076",
            "36c175a6bd464ae5bd7a6cc2f35bc8d5",
            "f0ebd1e4e29e4386a63e9472e5258a93",
            "dcc108cd001d483a9f9c11c37b2808a1",
            "585467f24b7742e6a939d670c5e7da01",
            "64541c6eae3747eb9e0e150f09dc7224",
            "39f13eab197447a99c137f2596502b88",
            "ef38adbcc97743d68b136bd410dd962b",
            "100b538473ff4e7daf8c5acf5c963e91",
            "e2dfda00146b46fc82e547d49284fbf5",
            "01c1381f1bc1410b9ffe28237964ef85",
            "9165620fe1ff42d8961425fa5aba1ed0",
            "1e30d61e5f894ce99eff2a197842c986",
            "375e4d9f0ab847709372084a573c7dbf",
            "efca6a7b92994943b3d80943cb5f8fb4",
            "800314547a1d41bc81b97bc48e92035c",
            "20f4d5b2c43f4332b6489c5a7abf8f11"
          ]
        },
        "id": "MJBbMZsmmYCb",
        "outputId": "f98f31ae-ba00-4fa5-a1da-7941ff1bb998"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/90 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "775749b482274e8da89378fc7e25bdd3"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/10 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "39f13eab197447a99c137f2596502b88"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Step 8: Define Training Arguments**"
      ],
      "metadata": {
        "id": "S0WN0T9NeC0a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ---- Step 8: Define Training Arguments ----\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=\"./results\",  # Where to store model checkpoints\n",
        "    num_train_epochs=3,  # Number of training epochs\n",
        "    per_device_train_batch_size=4,  # Batch size per GPU\n",
        "    per_device_eval_batch_size=4,  # Batch size for evaluation\n",
        "    gradient_accumulation_steps=1,  # Accumulate gradients over multiple steps\n",
        "    gradient_checkpointing=True,  # Enable gradient checkpointing to save memory\n",
        "    learning_rate=2e-4,  # Initial learning rate\n",
        "    weight_decay=0.01,  # Weight decay for regularization\n",
        "    optim=\"adamw_torch\",  # Optimizer to use\n",
        "    evaluation_strategy=\"steps\",  # Evaluate the model every few steps\n",
        "    save_strategy=\"steps\",  # Save model every few steps to match evaluation strategy\n",
        "    save_steps=500,  # Save checkpoint every 500 steps\n",
        "    save_total_limit=2,  # Save only the 2 latest checkpoints\n",
        "    load_best_model_at_end=True,  # Load the best model at the end\n",
        "    logging_steps=25,  # Log every 25 steps\n",
        "    # fp16=True,  # Enable FP16 precision for training on compatible GPUs\n",
        ")\n"
      ],
      "metadata": {
        "id": "fFSVhJsyeFcE"
      },
      "execution_count": 100,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Step 9: Define the Trainer**"
      ],
      "metadata": {
        "id": "ODmi7j4Gfzr9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_loss(model, inputs):\n",
        "    labels = inputs.pop(\"labels\")\n",
        "    # Ensure inputs require gradients\n",
        "    for key in inputs:\n",
        "        if isinstance(inputs[key], torch.Tensor):\n",
        "            inputs[key].requires_grad = True\n",
        "\n",
        "    outputs = model(**inputs)\n",
        "    logits = outputs.logits\n",
        "    loss_fn = torch.nn.CrossEntropyLoss()\n",
        "    num_labels = model.config.num_labels\n",
        "    loss = loss_fn(logits.view(-1, num_labels), labels.view(-1))\n",
        "    return loss"
      ],
      "metadata": {
        "id": "rHAlzaUtn5BM"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=valid_dataset,\n",
        "    tokenizer=tokenizer,\n",
        "    data_collator=data_collator,\n",
        "    callbacks=[EarlyStoppingCallback(early_stopping_patience=3)]\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K0dg8yGzf0BG",
        "outputId": "d4517094-a570-4779-db86-53d2613bffb9"
      },
      "execution_count": 101,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/accelerate/accelerator.py:494: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  self.scaler = torch.cuda.amp.GradScaler(**kwargs)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "training_arguments = TrainingArguments(\n",
        "    output_dir=output_dir,\n",
        "    num_train_epochs=3,  # Specify number of training epochs\n",
        "    per_device_train_batch_size=4,  # Adjust batch size according to your GPU memory\n",
        "    gradient_accumulation_steps=8,  # Adjust for larger effective batch size\n",
        "    optim=\"adamw_torch\",  # Optimizer to use\n",
        "    save_steps=500,  # Save model every 500 steps\n",
        "    logging_steps=25,  # Log every 25 steps\n",
        "    learning_rate=2e-4,  # Learning rate\n",
        "    weight_decay=0.01,  # Weight decay for regularization\n",
        "    fp16=True,  # Enable mixed precision if using GPU\n",
        "    bf16=False,  # Enable bf16 if compatible with your GPU\n",
        "    max_grad_norm=1.0,  # Gradient clipping\n",
        "    max_steps=-1,  # No max steps by default\n",
        "    warmup_ratio=0.03,  # Warmup steps as a percentage of total steps\n",
        "    group_by_length=True,  # Efficient memory usage by grouping sequences of the same length\n",
        "    lr_scheduler_type=\"cosine\",  # Learning rate scheduler\n",
        "    report_to=\"tensorboard\"  # Report to tensorboard\n",
        ")"
      ],
      "metadata": {
        "id": "nxbgv1237vO1"
      },
      "execution_count": 107,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainer = SFTTrainer(\n",
        "    model=model,\n",
        "    train_dataset=train_dataset,\n",
        "    peft_config=peft_config,\n",
        "    dataset_text_field=\"prompt\",  # Adjust this field according to your dataset\n",
        "    max_seq_length=512,  # Maximum sequence length\n",
        "    tokenizer=tokenizer,\n",
        "    args=training_arguments,\n",
        "    packing=False,  # Enable or disable sequence packing\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104,
          "referenced_widgets": [
            "08167a256250414fa23567ab452e2f10",
            "74d6c58237df484286d0b8659b32c374",
            "500eddb075b84ca5931f176ae40b84f1",
            "2e64ceb5a21241c9b1fb0e21c6278fa3",
            "b163bbc215be4369baf89b2f14bf377e",
            "cfa70b80466f4c49a880e3f5f13afb49",
            "b553ef035d894956891feb04229d4780",
            "367a31de22464d60b5f8faf05e2db578",
            "76014a32b7b34b66afad76f4c4849566",
            "160330be24de47f69c56e849a88a2eb7",
            "9d624850e7a545749b1eed481928ed5e"
          ]
        },
        "id": "1PVvtIZ47xM9",
        "outputId": "f71eb2e2-d337-4b9c-ae7a-cf90de6b3dc3"
      },
      "execution_count": 110,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/90 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "08167a256250414fa23567ab452e2f10"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/accelerate/accelerator.py:494: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  self.scaler = torch.cuda.amp.GradScaler(**kwargs)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Step 10: Fine-tune the Model**"
      ],
      "metadata": {
        "id": "zU2bljmtf50F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.train()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 234
        },
        "id": "tjuQykEN8AzO",
        "outputId": "8a094ba7-d03e-401f-dd3f-0bc5e3667fcd"
      },
      "execution_count": 111,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You're using a LlamaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
            "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/eval_frame.py:600: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n",
            "  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='6' max='6' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [6/6 00:31, Epoch 2/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TrainOutput(global_step=6, training_loss=0.8431399663289388, metrics={'train_runtime': 37.8044, 'train_samples_per_second': 7.142, 'train_steps_per_second': 0.159, 'total_flos': 1673530326466560.0, 'train_loss': 0.8431399663289388, 'epoch': 2.09})"
            ]
          },
          "metadata": {},
          "execution_count": 111
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Step 11: Save the Model and Tokenizer**"
      ],
      "metadata": {
        "id": "W-lQYudvgYm0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "save_path = \"/content/drive/MyDrive/fine_tuned_llama2_lora_qlora\""
      ],
      "metadata": {
        "id": "Hp11i5cCgZ09"
      },
      "execution_count": 112,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.save_model(save_path)  # Save model checkpoint\n",
        "tokenizer.save_pretrained(save_path)  # Save tokenizer\n",
        "print(f\"Model and tokenizer saved to {save_path}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lZTt3Bzdgdot",
        "outputId": "0efa4195-7f7c-48fc-9ccc-7df51210f498"
      },
      "execution_count": 113,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model and tokenizer saved to /content/drive/MyDrive/fine_tuned_llama2_lora_qlora\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Step 12: Load the Fine-Tuned Model**"
      ],
      "metadata": {
        "id": "ya1VBTaNg8gp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# After fine-tuning, save the model and tokenizer\n",
        "save_path = \"/content/drive/MyDrive/fine_tuned_llama2_lora_qlora\"\n",
        "\n",
        "model.save_pretrained(save_path)\n",
        "tokenizer.save_pretrained(save_path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Iu7MnFoupkkc",
        "outputId": "a35907b7-4d2e-4121-f0b6-6013cda0d9a4"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('/content/drive/MyDrive/fine_tuned_llama2_lora_qlora/tokenizer_config.json',\n",
              " '/content/drive/MyDrive/fine_tuned_llama2_lora_qlora/special_tokens_map.json',\n",
              " '/content/drive/MyDrive/fine_tuned_llama2_lora_qlora/tokenizer.model',\n",
              " '/content/drive/MyDrive/fine_tuned_llama2_lora_qlora/added_tokens.json')"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Step 13: Testing the Model with Text Generation**"
      ],
      "metadata": {
        "id": "DOKKcy8phF2h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "# Create a text-generation pipeline using the fine-tuned model\n",
        "pipe = pipeline(\"text-generation\", model=model, tokenizer=tokenizer, device=0)\n",
        "\n",
        "# Define a sample prompt for testing\n",
        "sample_prompt = \"[INST] <<SYS>>\\nWhat is the impact of climate change?\\n<</SYS>>\\n\\n\"\n",
        "\n",
        "# Generate a response\n",
        "generated_text = pipe(sample_prompt, max_length=200, num_return_sequences=1)\n",
        "\n",
        "# Print the generated response\n",
        "print(generated_text[0]['generated_text'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gMe7xZ9RhKQ1",
        "outputId": "4d29cdf0-57fa-416e-dd8a-dc7a492e89e9"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Xformers is not installed correctly. If you want to use memory_efficient_attention to accelerate training use the following command to install Xformers\n",
            "pip install xformers.\n",
            "The model 'PeftModelForCausalLM' is not supported for text-generation. Supported models are ['BartForCausalLM', 'BertLMHeadModel', 'BertGenerationDecoder', 'BigBirdForCausalLM', 'BigBirdPegasusForCausalLM', 'BioGptForCausalLM', 'BlenderbotForCausalLM', 'BlenderbotSmallForCausalLM', 'BloomForCausalLM', 'CamembertForCausalLM', 'CodeGenForCausalLM', 'CpmAntForCausalLM', 'CTRLLMHeadModel', 'Data2VecTextForCausalLM', 'ElectraForCausalLM', 'ErnieForCausalLM', 'FalconForCausalLM', 'GitForCausalLM', 'GPT2LMHeadModel', 'GPT2LMHeadModel', 'GPTBigCodeForCausalLM', 'GPTNeoForCausalLM', 'GPTNeoXForCausalLM', 'GPTNeoXJapaneseForCausalLM', 'GPTJForCausalLM', 'LlamaForCausalLM', 'MarianForCausalLM', 'MBartForCausalLM', 'MegaForCausalLM', 'MegatronBertForCausalLM', 'MusicgenForCausalLM', 'MvpForCausalLM', 'OpenLlamaForCausalLM', 'OpenAIGPTLMHeadModel', 'OPTForCausalLM', 'PegasusForCausalLM', 'PLBartForCausalLM', 'ProphetNetForCausalLM', 'QDQBertLMHeadModel', 'ReformerModelWithLMHead', 'RemBertForCausalLM', 'RobertaForCausalLM', 'RobertaPreLayerNormForCausalLM', 'RoCBertForCausalLM', 'RoFormerForCausalLM', 'RwkvForCausalLM', 'Speech2Text2ForCausalLM', 'TransfoXLLMHeadModel', 'TrOCRForCausalLM', 'XGLMForCausalLM', 'XLMWithLMHeadModel', 'XLMProphetNetForCausalLM', 'XLMRobertaForCausalLM', 'XLMRobertaXLForCausalLM', 'XLNetLMHeadModel', 'XmodForCausalLM'].\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1270: UserWarning: You have modified the pretrained model configuration to control generation. This is a deprecated strategy to control generation and will be removed soon, in a future version. Please use a generation configuration file (see https://huggingface.co/docs/transformers/main_classes/text_generation )\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[INST] <<SYS>>\n",
            "What is the impact of climate change?\n",
            "<</SYS>>\n",
            "\n",
            "Climate change is having a profound impact on the world around us. Rising temperatures are causing melting of polar ice caps, sea level rise, and more frequent and severe weather events such as heatwaves, droughts, and storms. This is having a cascading effect on ecosystems, biodiversity, and human societies.\n",
            "\n",
            "Some of the key impacts of climate change include:\n",
            "\n",
            "1. Extreme weather events: Climate change is leading to more frequent and severe heatwaves, droughts, and storms. This can have devastating effects on agriculture, infrastructure, and human health.\n",
            "2. Sea level rise: As the polar ice caps melt, sea levels are rising, leading to coastal erosion, flooding, and saltwater intrusion into\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Step 14:Testing the Model with Custom Inputs**"
      ],
      "metadata": {
        "id": "nldh-03ehOpi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define a sample input text\n",
        "input_text = \"[INST] <<SYS>>\\nProvide an analysis of stock market trends for the last year.\\n<SYS>>\\n\\n\"\n",
        "\n",
        "# Move the model to the GPU if available\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "# Tokenize the input text\n",
        "input_ids = tokenizer(input_text, return_tensors=\"pt\").input_ids.to(device)\n",
        "\n",
        "# Generate response from the model\n",
        "with torch.no_grad():\n",
        "    output_ids = model.generate(input_ids=input_ids, max_length=200)\n",
        "\n",
        "# Decode the output and print the response\n",
        "output_text = tokenizer.decode(output_ids[0], skip_special_tokens=True)\n",
        "print(output_text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7H1nNabqhOX8",
        "outputId": "def0f7fc-22be-4869-9f54-42b50b3216e5"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[INST] <<SYS>>\n",
            "Provide an analysis of stock market trends for the last year.\n",
            "<SYS>>\n",
            "\n",
            "Stock market trends can be analyzed using various methods, including technical analysis and fundamental analysis. Technical analysis focuses on identifying patterns and trends in stock prices, while fundamental analysis examines a company's financial health and other factors that may impact its stock price.\n",
            "\n",
            "Here are some key trends that have emerged in the stock market over the last year:\n",
            "\n",
            "1. Market volatility: The stock market has been experiencing increased volatility in recent months, with sharp price swings and sudden changes in investor sentiment. This volatility has been driven by a range of factors, including geopolitical tensions, central bank policies, and economic uncertainty.\n",
            "2. Sector rotation: There has been a significant rotation in the stock market over the last year, with certain se\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pipe = pipeline(task=\"text-generation\", model=model, tokenizer=tokenizer, max_length=200)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DatYAwiirHfX",
        "outputId": "b39c1fe2-e3c3-4d62-d752-503f93734fb3"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The model 'PeftModelForCausalLM' is not supported for text-generation. Supported models are ['BartForCausalLM', 'BertLMHeadModel', 'BertGenerationDecoder', 'BigBirdForCausalLM', 'BigBirdPegasusForCausalLM', 'BioGptForCausalLM', 'BlenderbotForCausalLM', 'BlenderbotSmallForCausalLM', 'BloomForCausalLM', 'CamembertForCausalLM', 'CodeGenForCausalLM', 'CpmAntForCausalLM', 'CTRLLMHeadModel', 'Data2VecTextForCausalLM', 'ElectraForCausalLM', 'ErnieForCausalLM', 'FalconForCausalLM', 'GitForCausalLM', 'GPT2LMHeadModel', 'GPT2LMHeadModel', 'GPTBigCodeForCausalLM', 'GPTNeoForCausalLM', 'GPTNeoXForCausalLM', 'GPTNeoXJapaneseForCausalLM', 'GPTJForCausalLM', 'LlamaForCausalLM', 'MarianForCausalLM', 'MBartForCausalLM', 'MegaForCausalLM', 'MegatronBertForCausalLM', 'MusicgenForCausalLM', 'MvpForCausalLM', 'OpenLlamaForCausalLM', 'OpenAIGPTLMHeadModel', 'OPTForCausalLM', 'PegasusForCausalLM', 'PLBartForCausalLM', 'ProphetNetForCausalLM', 'QDQBertLMHeadModel', 'ReformerModelWithLMHead', 'RemBertForCausalLM', 'RobertaForCausalLM', 'RobertaPreLayerNormForCausalLM', 'RoCBertForCausalLM', 'RoFormerForCausalLM', 'RwkvForCausalLM', 'Speech2Text2ForCausalLM', 'TransfoXLLMHeadModel', 'TrOCRForCausalLM', 'XGLMForCausalLM', 'XLMWithLMHeadModel', 'XLMProphetNetForCausalLM', 'XLMRobertaForCausalLM', 'XLMRobertaXLForCausalLM', 'XLNetLMHeadModel', 'XmodForCausalLM'].\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Implementation for Sentiment Analysis Testing**"
      ],
      "metadata": {
        "id": "-rV8MxnEqjBl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_sentiment(text):\n",
        "    # Tokenize the input text\n",
        "    inputs = tokenizer(text, return_tensors=\"pt\").to(device)\n",
        "\n",
        "    # Generate prediction\n",
        "    with torch.no_grad():\n",
        "        # Enable memory efficient attention\n",
        "        with torch.backends.cuda.sdp_kernel(enable_flash=True, enable_math=True, enable_mem_efficient=True):\n",
        "            outputs = model(**inputs)\n",
        "        logits = outputs.logits\n",
        "\n",
        "    # Get the predicted class (1 for positive, 0 for negative)\n",
        "    # Calculate the average of the logits across all 32000 elements\n",
        "    predicted_class = torch.argmax(torch.mean(logits, dim=1)).item()\n",
        "    return predicted_class"
      ],
      "metadata": {
        "id": "Vv_-TxxWqahu"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ---- Example usage for sentiment analysis ----\n",
        "text = \"[INST] <<SYS>>\\nAnalyze sentiment for: 'The product is not performing as expected.'\\n<SYS>>\\n\\n\"\n",
        "predicted_class = predict_sentiment(text)\n",
        "if predicted_class == 1:\n",
        "    print(\"Positive Sentiment\")\n",
        "else:\n",
        "    print(\"Negative Sentiment\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YxdwuHRvqwLe",
        "outputId": "b14d8c44-5546-4fdf-f7f0-b78e67f26052"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Negative Sentiment\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/lib/python3.10/contextlib.py:103: FutureWarning: `torch.backends.cuda.sdp_kernel()` is deprecated. In the future, this context manager will be removed. Please see `torch.nn.attention.sdpa_kernel()` for the new context manager, with updated signature.\n",
            "  self.gen = func(*args, **kwds)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Test Example:**"
      ],
      "metadata": {
        "id": "sc54-E4mqpDl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Example usage for a multi-class model\n",
        "text = \"[INST] <<SYS>>\\nAnalyze sentiment for: 'The service is decent but not great.'\\n<</SYS>>\\n\\n\"\n",
        "predicted_class = predict_sentiment(text)\n",
        "\n",
        "# Interpret the predicted class (assuming 0 = negative, 1 = neutral, 2 = positive)\n",
        "if predicted_class == 0:\n",
        "    print(\"Negative Sentiment\")\n",
        "elif predicted_class == 1:\n",
        "    print(\"Neutral Sentiment\")\n",
        "elif predicted_class == 2:\n",
        "    print(\"Positive Sentiment\")"
      ],
      "metadata": {
        "id": "lJDwcyyfqqbc"
      },
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ---- Example usage for sentiment analysis ----\n",
        "text = \"[INST] <<SYS>>\\nProvide an analysis of stock market trends for the last year.\\n<</SYS>>\\n\\n\"\n",
        "predicted_class = predict_sentiment(text)\n",
        "if predicted_class == 1:\n",
        "    print(\"Positive Sentiment\")\n",
        "else:\n",
        "    print(\"Negative Sentiment\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7GUMRxNy1m32",
        "outputId": "c8b7f9b1-2fc5-4573-ae0d-1218636bb96a"
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Negative Sentiment\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input_text = \"[INST] <<SYS>>\\nProvide an analysis of stock market trends for the last year.\\n<</SYS>>\\n\\n\"\n",
        "\n",
        "# Tokenize the input text\n",
        "input_ids = tokenizer(input_text, return_tensors=\"pt\").input_ids.to(device)\n",
        "\n",
        "# Generate response from the base model\n",
        "with torch.no_grad():\n",
        "    # Access the base model and generate the response\n",
        "    # Use keyword arguments instead of positional arguments\n",
        "    output_ids = model.base_model.generate(input_ids=input_ids, max_length=200)\n",
        "\n",
        "# Decode the output and print the response\n",
        "output_text = tokenizer.decode(output_ids[0], skip_special_tokens=True)\n",
        "print(output_text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5kcio2SurDav",
        "outputId": "a54f9ae9-b216-4d7c-8526-fb2009662330"
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[INST] <<SYS>>\n",
            "Provide an analysis of stock market trends for the last year.\n",
            "<</SYS>>\n",
            "\n",
            "Please provide a detailed analysis of the stock market trends for the last year, including:\n",
            "\n",
            "1. Overall market performance\n",
            "2. Sector performance\n",
            "3. Market volatility\n",
            "4. Investor sentiment\n",
            "5. Economic indicators\n",
            "6. Geopolitical events\n",
            "7. Central bank actions\n",
            "8. Market structure\n",
            "\n",
            "Please provide your analysis in a clear and concise manner, including charts and graphs to support your points.\n",
            "\n",
            "Thank you.\n",
            "\n",
            "---\n",
            "\n",
            "Analysis of Stock Market Trends for the Last Year\n",
            "\n",
            "Overall Market Performance:\n",
            "The overall performance of the stock market for the last year has been mixed. The S&P 500 index, which is widely considered a benchmark for the US stock market, has gained around 25%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Define the prompt\n",
        "prompt = \"[INST] <<SYS>>\\nPerform sentiment analysis\\n<SYS>>\\n\\nApple stock is performing well. [/INST]\"\n",
        "\n",
        "# Initialize the pipeline and move the model to the device\n",
        "pipe = pipeline(\"text-generation\", model=model, tokenizer=tokenizer, device=0 if device == torch.device(\"cuda\") else -1)\n",
        "\n",
        "# Generate the response\n",
        "result = pipe(prompt)\n",
        "\n",
        "# Output the generated text\n",
        "print(result[0]['generated_text'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Je8THMoarp3Y",
        "outputId": "d258e0cb-f6ee-4f7f-e094-0051e78896aa"
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The model 'PeftModelForCausalLM' is not supported for text-generation. Supported models are ['BartForCausalLM', 'BertLMHeadModel', 'BertGenerationDecoder', 'BigBirdForCausalLM', 'BigBirdPegasusForCausalLM', 'BioGptForCausalLM', 'BlenderbotForCausalLM', 'BlenderbotSmallForCausalLM', 'BloomForCausalLM', 'CamembertForCausalLM', 'CodeGenForCausalLM', 'CpmAntForCausalLM', 'CTRLLMHeadModel', 'Data2VecTextForCausalLM', 'ElectraForCausalLM', 'ErnieForCausalLM', 'FalconForCausalLM', 'GitForCausalLM', 'GPT2LMHeadModel', 'GPT2LMHeadModel', 'GPTBigCodeForCausalLM', 'GPTNeoForCausalLM', 'GPTNeoXForCausalLM', 'GPTNeoXJapaneseForCausalLM', 'GPTJForCausalLM', 'LlamaForCausalLM', 'MarianForCausalLM', 'MBartForCausalLM', 'MegaForCausalLM', 'MegatronBertForCausalLM', 'MusicgenForCausalLM', 'MvpForCausalLM', 'OpenLlamaForCausalLM', 'OpenAIGPTLMHeadModel', 'OPTForCausalLM', 'PegasusForCausalLM', 'PLBartForCausalLM', 'ProphetNetForCausalLM', 'QDQBertLMHeadModel', 'ReformerModelWithLMHead', 'RemBertForCausalLM', 'RobertaForCausalLM', 'RobertaPreLayerNormForCausalLM', 'RoCBertForCausalLM', 'RoFormerForCausalLM', 'RwkvForCausalLM', 'Speech2Text2ForCausalLM', 'TransfoXLLMHeadModel', 'TrOCRForCausalLM', 'XGLMForCausalLM', 'XLMWithLMHeadModel', 'XLMProphetNetForCausalLM', 'XLMRobertaForCausalLM', 'XLMRobertaXLForCausalLM', 'XLNetLMHeadModel', 'XmodForCausalLM'].\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1369: UserWarning: Using `max_length`'s default (20) to control the generation length. This behaviour is deprecated and will be removed from the config in v5 of Transformers -- we recommend using `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "Input length of input_ids is 30, but `max_length` is set to 20. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[INST] <<SYS>>\n",
            "Perform sentiment analysis\n",
            "<SYS>>\n",
            "\n",
            "Apple stock is performing well. [/INST] \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the LoRA model using PeftModel if necessary\n",
        "model = PeftModel.from_pretrained(model, \"/content/drive/MyDrive/model_Train_Assingnment/llama2-fine-tuned-sentiment/\")\n",
        "\n",
        "pipe = pipeline(task=\"text-generation\", model=model, tokenizer=tokenizer, max_length=200)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-8cGDpsDrWC1",
        "outputId": "130ce219-1377-4416-b9ea-1dddf9beaeee"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/peft/peft_model.py:556: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  adapters_weights = torch.load(\n",
            "The model 'PeftModelForCausalLM' is not supported for text-generation. Supported models are ['BartForCausalLM', 'BertLMHeadModel', 'BertGenerationDecoder', 'BigBirdForCausalLM', 'BigBirdPegasusForCausalLM', 'BioGptForCausalLM', 'BlenderbotForCausalLM', 'BlenderbotSmallForCausalLM', 'BloomForCausalLM', 'CamembertForCausalLM', 'CodeGenForCausalLM', 'CpmAntForCausalLM', 'CTRLLMHeadModel', 'Data2VecTextForCausalLM', 'ElectraForCausalLM', 'ErnieForCausalLM', 'FalconForCausalLM', 'GitForCausalLM', 'GPT2LMHeadModel', 'GPT2LMHeadModel', 'GPTBigCodeForCausalLM', 'GPTNeoForCausalLM', 'GPTNeoXForCausalLM', 'GPTNeoXJapaneseForCausalLM', 'GPTJForCausalLM', 'LlamaForCausalLM', 'MarianForCausalLM', 'MBartForCausalLM', 'MegaForCausalLM', 'MegatronBertForCausalLM', 'MusicgenForCausalLM', 'MvpForCausalLM', 'OpenLlamaForCausalLM', 'OpenAIGPTLMHeadModel', 'OPTForCausalLM', 'PegasusForCausalLM', 'PLBartForCausalLM', 'ProphetNetForCausalLM', 'QDQBertLMHeadModel', 'ReformerModelWithLMHead', 'RemBertForCausalLM', 'RobertaForCausalLM', 'RobertaPreLayerNormForCausalLM', 'RoCBertForCausalLM', 'RoFormerForCausalLM', 'RwkvForCausalLM', 'Speech2Text2ForCausalLM', 'TransfoXLLMHeadModel', 'TrOCRForCausalLM', 'XGLMForCausalLM', 'XLMWithLMHeadModel', 'XLMProphetNetForCausalLM', 'XLMRobertaForCausalLM', 'XLMRobertaXLForCausalLM', 'XLNetLMHeadModel', 'XmodForCausalLM'].\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary libraries\n",
        "from transformers import pipeline, LlamaTokenizer, LlamaForCausalLM\n",
        "\n",
        "# Function to analyze sentiment and generate reasoning\n",
        "def sentiment_analysis_with_reasoning(prompt):\n",
        "    # Generate text with the fine-tuned model\n",
        "    # Removed the truncation argument\n",
        "    result = pipe(prompt)\n",
        "\n",
        "    # Extract the generated response\n",
        "    generated_text = result[0]['generated_text']\n",
        "\n",
        "    # Analyzing the sentiment based on the generated text\n",
        "    if \"positive\" in generated_text.lower():\n",
        "        sentiment = \"Positive\"\n",
        "        reasoning = \"The statement implies a positive trend or improvement, which is a good indication.\"\n",
        "    elif \"negative\" in generated_text.lower():\n",
        "        sentiment = \"Negative\"\n",
        "        reasoning = \"The statement implies a negative trend or decrease, which is a bad indication.\"\n",
        "    else:\n",
        "        sentiment = \"Neutral\"\n",
        "        reasoning = \"The statement does not imply strong positive or negative trends.\"\n",
        "\n",
        "    # Format the output\n",
        "    output = f\"{generated_text}\\n\\nSentiment: {sentiment}\\nReasoning: {reasoning}\"\n",
        "    return output\n",
        "\n",
        "# Test the model with a sample prompt\n",
        "prompt = \"[INST] <<SYS>>\\nPerform sentiment analysis\\n<SYS>>\\n\\nApple stock is performing well. [/INST]\"\n",
        "\n",
        "# Run the analysis and get the result\n",
        "analysis_result = sentiment_analysis_with_reasoning(prompt)\n",
        "\n",
        "# Output the result\n",
        "print(analysis_result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4Rb22GyTrYmj",
        "outputId": "a6c51082-760d-4f40-e1ab-5d96251d0b6c"
      },
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Input length of input_ids is 30, but `max_length` is set to 20. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[INST] <<SYS>>\n",
            "Perform sentiment analysis\n",
            "<SYS>>\n",
            "\n",
            "Apple stock is performing well. [/INST] \n",
            "\n",
            "Sentiment: Neutral\n",
            "Reasoning: The statement does not imply strong positive or negative trends.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Evaluate the Model on a Validation or Test Dataset**"
      ],
      "metadata": {
        "id": "I_aFZuZ5scuD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import locale\n",
        "locale.setlocale(locale.LC_ALL, 'C.UTF-8')\n",
        "\n",
        "# Step 2: Install the evaluate library\n",
        "!pip install evaluate"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zn5fCRx1v6B8",
        "outputId": "7103d4ed-1f28-4a9b-e9d8-d9085274c9e2"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting evaluate\n",
            "  Downloading evaluate-0.4.3-py3-none-any.whl.metadata (9.2 kB)\n",
            "Requirement already satisfied: datasets>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from evaluate) (3.0.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from evaluate) (1.26.4)\n",
            "Requirement already satisfied: dill in /usr/local/lib/python3.10/dist-packages (from evaluate) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from evaluate) (2.1.4)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from evaluate) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.10/dist-packages (from evaluate) (4.66.5)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from evaluate) (3.5.0)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.10/dist-packages (from evaluate) (0.70.16)\n",
            "Requirement already satisfied: fsspec>=2021.05.0 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]>=2021.05.0->evaluate) (2024.6.1)\n",
            "Requirement already satisfied: huggingface-hub>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from evaluate) (0.24.7)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from evaluate) (24.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (3.16.1)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (17.0.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (3.10.5)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (6.0.2)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.7.0->evaluate) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate) (2024.8.30)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->evaluate) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->evaluate) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas->evaluate) (2024.1)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (2.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (6.1.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.11.1)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (4.0.3)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->evaluate) (1.16.0)\n",
            "Downloading evaluate-0.4.3-py3-none-any.whl (84 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.0/84.0 kB\u001b[0m \u001b[31m899.1 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: evaluate\n",
            "Successfully installed evaluate-0.4.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import locale\n",
        "try:\n",
        "    locale.setlocale(locale.LC_ALL, 'C.UTF-8')\n",
        "except locale.Error as e:\n",
        "    print(f\"Locale setting failed: {e}\")"
      ],
      "metadata": {
        "id": "jaUnl6QJwaRl"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Generate Multiple Predictions (for Batch Testing)**"
      ],
      "metadata": {
        "id": "d452FDGUsltc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Example list of prompts for batch testing\n",
        "prompts = [\n",
        "    \"[INST] <<SYS>>\\nExplain the impact of artificial intelligence in healthcare.\\n<</SYS>>\\n\\n\",\n",
        "    \"[INST] <<SYS>>\\nDescribe the significance of data privacy in modern technologies.\\n<SYS>>\\n\\n\",\n",
        "    \"[INST] <<SYS>>\\nWhat are the recent advancements in quantum computing?\\n<SYS>>\\n\\n\"\n",
        "]\n",
        "\n",
        "# Generate responses for all prompts\n",
        "for prompt in prompts:\n",
        "    input_ids = tokenizer(prompt, return_tensors=\"pt\").input_ids.to(device)\n",
        "    # Pass generation parameters as a dictionary\n",
        "    output_ids = model.generate(**{'input_ids': input_ids, 'max_length': 200})\n",
        "    output_text = tokenizer.decode(output_ids[0], skip_special_tokens=True)\n",
        "    print(f\"Prompt: {prompt}\\nResponse: {output_text}\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u1bot34MtFWu",
        "outputId": "07dc9597-72be-4980-e32f-915e281fb3f4"
      },
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prompt: [INST] <<SYS>>\n",
            "Explain the impact of artificial intelligence in healthcare.\n",
            "<</SYS>>\n",
            "\n",
            "\n",
            "Response: [INST] <<SYS>>\n",
            "Explain the impact of artificial intelligence in healthcare.\n",
            "<</SYS>>\n",
            "\n",
            "Artificial intelligence (AI) is transforming the healthcare industry in various ways, from improving patient outcomes to streamlining clinical workflows. Here are some of the key impacts of AI in healthcare:\n",
            "\n",
            "1. Personalized medicine: AI can help personalize treatment plans for patients based on their individual characteristics, such as genetic profiles, medical history, and lifestyle.\n",
            "2. Disease diagnosis: AI-powered diagnostic tools can analyze medical images and patient data to help doctors diagnose diseases more accurately and quickly.\n",
            "3. Drug discovery: AI can help researchers identify potential drug targets and develop new drugs by analyzing large amounts of biomedical data.\n",
            "4. Predictive analytics: AI-powered predict\n",
            "\n",
            "Prompt: [INST] <<SYS>>\n",
            "Describe the significance of data privacy in modern technologies.\n",
            "<SYS>>\n",
            "\n",
            "\n",
            "Response: [INST] <<SYS>>\n",
            "Describe the significance of data privacy in modern technologies.\n",
            "<SYS>>\n",
            "\n",
            "Data privacy is a critical aspect of modern technologies, as it refers to the protection of personal information from unauthorized access, use, or disclosure. With the increasing use of digital technologies, the amount of personal data being collected, stored, and shared has grown exponentially, raising concerns about how this data is being used and protected. Here are some reasons why data privacy is significant in modern technologies:\n",
            "\n",
            "1. Protection of personal information: Data privacy is essential for protecting personal information, such as names, addresses, phone numbers, and financial information, from unauthorized access or misuse. This is particularly important in today's digital age, where personal information is often collected, stored, and shared electronically.\n",
            "2. Prevention of identity theft: Identity theft is a\n",
            "\n",
            "Prompt: [INST] <<SYS>>\n",
            "What are the recent advancements in quantum computing?\n",
            "<SYS>>\n",
            "\n",
            "\n",
            "Response: [INST] <<SYS>>\n",
            "What are the recent advancements in quantum computing?\n",
            "<SYS>>\n",
            "\n",
            "Quantum computing is a rapidly advancing field, and there have been many recent advancements in this area. Here are some of the most notable ones:\n",
            "\n",
            "1. Quantum Processors: Several companies, including IBM, Google, and Rigetti Computing, have developed quantum processors that can perform quantum computations with a high degree of accuracy. These processors are based on different technologies, such as superconducting circuits, ion traps, or quantum dots.\n",
            "2. Quantum Error Correction: Quantum error correction is a critical technology for large-scale quantum computing. Researchers have developed new codes and algorithms to detect and correct errors in quantum computations, which is essential for scaling up quantum computing.\n",
            "3. Quantum Machine Learning: Quantum machine learning is an emerging field that expl\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Save and Export Results**"
      ],
      "metadata": {
        "id": "MwuDSnneteCl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Example of saving generated responses to a CSV file\n",
        "responses = []\n",
        "prompts = [\"What is AI?\", \"How does machine learning work?\"]  # Replace with actual prompts\n",
        "for prompt in prompts:\n",
        "    input_ids = tokenizer(prompt, return_tensors=\"pt\").input_ids.to(device)\n",
        "    output_ids = model.generate(input_ids, max_length=200)\n",
        "    output_text = tokenizer.decode(output_ids[0], skip_special_tokens=True)\n",
        "    responses.append({\"Prompt\": prompt, \"Response\": output_text})\n",
        "\n",
        "# Convert to DataFrame and save to CSV\n",
        "df = pd.DataFrame(responses)\n",
        "df.to_csv(\"/content/drive/MyDrive/generated_responses.csv\", index=False)\n"
      ],
      "metadata": {
        "id": "tZFfqK5etde9"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}